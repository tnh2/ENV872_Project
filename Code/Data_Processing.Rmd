---
title: "Data Processing"
author: "Thomas Hancock"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

## Overview
This script loads in the data to be analyzed and processes the data so they are ready for exploration later.

## Load Packages
This section loads the requisite packages and establishes the workspace

```{r Workspace Setup, message = FALSE}

getwd() # Check working directory

library(tidyverse)
library(lubridate)
library(knitr)
library(dplyr)
library(viridis)
library(RColorBrewer)
library(here)
library(sf)
library(ggmap)
library(cowplot)

# Set theme
mytheme <- theme_classic() +
  theme(axis.text = element_text(color = "black"), 
        legend.position = "top")
theme_set(mytheme)

```

## Load Data
This section loads the raw data

```{r Load GIS Data}

# Load geospatial data for coal mines
mines <- st_read(here("Data", "Raw", "Spatial", "CoalMines_US_2018.shp"))
class(mines) # Check filetype

# Load state boundary shapefiles
state_bounds <- st_read(here("Data", "Raw", "Spatial", "tl_2019_us_state.shp"))
class(state_bounds) # Check filetype

# Load county boundary shapefiles
county_bounds <- st_read(here("Data", "Raw", "Spatial", "tl_2019_us_county.shp"))
class(county_bounds) # Check filetype

```


```{r Load Tabular Data}

# Load COVID rates data
covid_all_raw <- read.csv(here("Data", "Raw", "COVID_County_04-23-2020.csv"))

# Load population data
pop_all_raw <- read.csv(here("Data", "Raw", "co-est2019-alldata.csv"))

```


## Geospatial Analysis
This section selects the counties that have coal mines

```{r Geospatial}
# Set base projections 
base_epsg <- st_crs(mines)[1]
base_proj <- st_crs(county_bounds)[2]

# Transform into the same coordinate system
state_bounds_WGS <- st_transform(state_bounds, as.numeric(base_epsg))
county_bounds_WGS <- st_transform(county_bounds, as.numeric(base_epsg))
#coal_counties_spatial <- st_intersection(county_bounds_WGS, mines)
coal_counties_spatial <- st_intersection(mines, county_bounds_WGS)
coal_counties_tab <- st_drop_geometry(coal_counties_spatial)

# Add leading zeros to FIPS codes
mines$mstafips <- sprintf("%02i", mines$mstafips)
mines$mctyfips <- sprintf("%03i", mines$mctyfips)
mines <- mutate(mines, FIPS = paste0(mstafips, mctyfips))

```

## Join Data
This section joins the tabular data with the geospatial data for the counties

```{r Data Joining}
# Clean County Population Data so it only contains 2019 population

# Tidy up COVID data to only include necessary information
covid_all_processed <- covid_all_raw %>%
  select(FIPS, Confirmed, Deaths) %>%
  na.exclude(FIPS)
covid_all_processed$FIPS <- sprintf("%05i", covid_all_processed$FIPS) # Convert to 5 digits

# Select for subset of columns
pop_processed <- pop_all_raw %>%
  select(STATE, COUNTY, STNAME, CTYNAME, POPESTIMATE2019) %>%
  filter(COUNTY > 0) %>% # Remove aggregated state values
  droplevels()

# Select values for entire state
pop_states <- pop_all_raw %>%
  select(STATE, COUNTY, STNAME, CTYNAME, POPESTIMATE2019) %>%
  filter(COUNTY == 0) %>%
  droplevels()

# Get FIPS codes
pop_processed$STATE <- sprintf("%02d", pop_processed$STATE)
pop_processed$COUNTY <- sprintf("%03d", pop_processed$COUNTY) # Add leading 0s to County code

# Add columns with calculated COVID-19 metrics
pop_processed <- pop_processed %>%  
  mutate(FIPS = paste0(STATE, COUNTY)) %>%
  full_join(covid_all_processed) %>%
  mutate(case_rate = Confirmed / POPESTIMATE2019 * 100000,
         death_rate_conf = Deaths / Confirmed,
         death_rate_pop = Deaths / POPESTIMATE2019 * 100000) %>%
  left_join(count(coal_counties_tab, GEOID, name = "Mines"), c("FIPS" = "GEOID"))

# Tidy column with number of mines
pop_processed$Mines <- replace_na(pop_processed$Mines, 0)

# Add column with label for counties with mines or without mines
pop_processed <- pop_processed %>%
  mutate(Mines.Label = Mines > 0)

pop_processed$Mines.Label[pop_processed$Mines.Label == TRUE] <- "Mines"
pop_processed$Mines.Label[pop_processed$Mines.Label == FALSE] <- "No Mines"
  
# Save data
write.csv(pop_processed, here("Data", "Processed", "County_Pop_COVID_Processed.csv"))

```

## Subset Data
This section subsets the data into smaller datasets specific to the states being analyzed (Pennsylvania and West Virignia). The counties are also filtered so only counties with 80% of the maximum population are included (this step is to remove the most populous counties that have major cities (e.g., Philadelphia, Charleston).

```{r Data Subsetting}
# Select just PA data
PA.Pop <- filter(pop_processed, STNAME == "Pennsylvania" & death_rate_conf < 0.5)
PA.Small <- filter(PA.Pop, POPESTIMATE2019 <= 0.8*max(PA.Pop$POPESTIMATE2019))
PA.Small.Mines <- filter(PA.Small, Mines.Label == "Mines") # Not Used in Report
PA.Small.NoMines <- filter(PA.Small, Mines.Label == "No Mines") # Not Used in Report

# Save PA data
write.csv(PA.Pop, here("Data", "Processed", "PA.Pop_processed.csv"))

# Select just WV Data
WV.Pop <- filter(pop_processed, STNAME == "West Virginia" & death_rate_conf < 0.5)
WV.Small <- filter(WV.Pop, POPESTIMATE2019 <= 0.8*max(WV.Pop$POPESTIMATE2019))
WV.Small.Mines <- filter(WV.Small, Mines.Label == "Mines") # Not Used in Report
WV.Small.NoMines <- filter(WV.Small, Mines.Label == "No Mines") # Not Used in Report

# Save WV data
write.csv(WV.Pop, here("Data", "Processed", "WV.Pop_processed.csv"))
```

## Data Aggregation -- Old data cleanup - redundant after changes earlier
This section finalizes the data aggregation to get data sets for comparison groups that include population data, covid data, and calculated covid rates (per 100,000 persons).

```{r Data Aggregation}
coal_counties_data <- pop_processed %>%
  filter(FIPS %in% coal_counties_tab$GEOID) %>%
  droplevels() %>%
  mutate(case_rate = Confirmed / POPESTIMATE2019 * 100000,
         death_rate_conf = Deaths / Confirmed,
         death_rate_pop = Deaths / POPESTIMATE2019 * 100000)


write.csv(coal_counties_data, here("Data", "Processed", "Coal_Counties_Data.csv"))


coal_state_cases <- pop_processed %>%
  group_by(STNAME) %>%
  filter(STNAME %in% levels(coal_counties_data$STNAME)) %>%
  droplevels() %>%
  summarise(Confirmed = sum(Confirmed, na.rm = TRUE),
            Deaths = sum(Deaths, na.rm = TRUE),
            POPESTIMATE2019 = sum(POPESTIMATE2019, na.rm = TRUE),
            Mines = sum(Mines, na.rm = TRUE)) %>%
  mutate(case_rate = Confirmed / POPESTIMATE2019 * 100000,
         death_rate_conf = Deaths / Confirmed,
         death_rate_pop = Deaths / POPESTIMATE2019 * 100000)

write(coal_state_cases, here("Data", "Processed", "Coal_State_Cases.csv"))

'%notin%' <- Negate('%in%')

not_coal_state_cases <- pop_processed %>%
  group_by(STNAME) %>%
  filter(STNAME %notin% levels(coal_state_cases$STNAME)) %>%
  droplevels() %>%
  summarise(Confirmed = sum(Confirmed, na.rm = TRUE),
            Deaths = sum(Deaths, na.rm = TRUE),
            POPESTIMATE2019 = sum(POPESTIMATE2019, na.rm = TRUE)) %>%
  mutate(case_rate = Confirmed / POPESTIMATE2019 * 100000,
         death_rate_conf = Deaths / Confirmed,
         death_rate_pop = Deaths / POPESTIMATE2019 * 100000) %>%
  na.omit()

write.csv(not_coal_state_cases, here("Data", "Processed", "Not_Coal_State_Cases.csv"))

```

## Air Quality Data -- NOT USED IN FINAL REPORT
I tried bringing some air quality data into this analyis, but it did not end up providing much additional insight. It is still included in this code, but not in the report.

```{r Air Quality, eval=FALSE, include=FALSE}

PA_Ozone <- read.csv(here("Data", "Raw", "PA_Ozone_Daily_041620.csv"))
PA_Ozone <- mutate(PA_Ozone, Pollutant = "Ozone_AQI")

PA_PM25 <- read.csv(here("Data", "Raw", "PA_PM25_Daily_041620.csv"))
PA_PM25 <- mutate(PA_PM25, Pollutant = "PM2.5_AQI")

PA_AQS_Combined <- full_join(PA_Ozone, PA_PM25)
PA_AQS_Combined$Date <- as.Date(PA_AQS_Combined$Date, "%m/%d/%Y")

PA_AQS_Processed <- PA_AQS_Combined %>%
  select(Date, Site.ID, Pollutant, Daily.Max.8.hour.Ozone.Concentration, DAILY_AQI_VALUE,
         Daily.Mean.PM2.5.Concentration, STATE_CODE, COUNTY_CODE,
         SITE_LATITUDE, SITE_LONGITUDE) %>%
  spread(Pollutant, DAILY_AQI_VALUE) %>%
  filter(Date <= as.Date("2020-04-16"))

PA_AQS_Summary <- PA_AQS_Processed %>%
  group_by(COUNTY_CODE) %>%
  summarise(Avg.Max.Ozone = mean(Daily.Max.8.hour.Ozone.Concentration, na.rm = TRUE),
            Avg.Ozone.AQI = mean(Ozone_AQI, na.rm = TRUE),
            Avg.Mean.PM25 = mean(Daily.Mean.PM2.5.Concentration, na.rm = TRUE),
            Avg.PM25.AQI = mean(PM2.5_AQI, na.rm = TRUE),
            SITE_LATITUDE = mean(SITE_LATITUDE, na.rm = TRUE),
            SITE_LONGITUDE = mean(SITE_LONGITUDE, na.rm = TRUE)) %>%
  mutate(FIPS = paste0(42, sprintf("%03d", COUNTY_CODE)))

PA_AQS_COVID <- left_join(PA_AQS_Summary, filter(pop_processed, STATE == 42))

write.csv(PA_AQS_Processed, here("Data", "Processed", "PA_AQS_Processed.csv"))
write.csv(PA_AQS_COVID, here("Data", "Processed", "PA_AQS_COVID.csv"))

```

